{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9490, 0.3459, 0.7848, 0.2402],\n",
       "        [0.0474, 0.5377, 0.1501, 0.4117],\n",
       "        [0.4782, 0.8456, 0.2781, 0.7196]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3,4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9490, 0.3459, 0.7848, 0.2402],\n",
      "        [0.0474, 0.5377, 0.1501, 0.4117],\n",
      "        [0.4782, 0.8456, 0.2781, 0.7196]])\n",
      "Datatype of the tensor: torch.float32\n",
      "Shape of tensor:  torch.Size([3, 4])\n",
      "Device tensor is on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Find out details about the tensor\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of the tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor:  {some_tensor.shape}\")\n",
    "print(f\"Device tensor is on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manupilating Tensors (operations)\n",
    "\n",
    "Tensor operations:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (Elementwise)\n",
    "* Division\n",
    "* Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and add 10 to it\n",
    "\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtraction\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Built in mul functions\n",
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "\n",
    "2 ways of doing multiplication: \n",
    "* elementwise \n",
    "* matrix multiplication (@ or 'torch.matmul()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Elementwise\n",
    "print(tensor, '*', tensor)\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Matrix\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Matrix multiplication by hand\n",
    "val = 0\n",
    "for i in range(len(tensor)):\n",
    "    val += tensor[i] * tensor[i]\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal tensor: \n",
      " tensor([[0.2698, 0.3393],\n",
      "        [0.9117, 0.6107],\n",
      "        [0.1558, 0.7764]])\n",
      "\n",
      "Tensor transpose: \n",
      " tensor([[0.2698, 0.9117, 0.1558],\n",
      "        [0.3393, 0.6107, 0.7764]])\n"
     ]
    }
   ],
   "source": [
    "# Transposing can be done by .T\n",
    "tensorB = torch.rand(size=(3,2))\n",
    "print (\"Orignal tensor: \\n\", tensorB)\n",
    "print(\"\\nTensor transpose: \\n\", tensorB.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Aggregation\n",
    "\n",
    "Finding the:\n",
    "* Min\n",
    "* Max\n",
    "* Mean\n",
    "* Sum and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "\n",
    "x= torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x), x.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x.type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns position (index value) of min value.\n",
    "torch.argmin(x), x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9), tensor(9))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns position (index value) of max value.\n",
    "torch.argmax(x), x.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping, stacking and unstacking tensors\n",
    "* Reshaping - reshapes and inputs tensors to a defined shape\n",
    "* View - Returns a view of an input tensor of certain shape but keep the same memory as the orignal tensor\n",
    "* Stacking - combine multiple tensors on top og each other (vstack) or sife by side (hstack)\n",
    "* Squeeze - removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - add a `1` dimension to a target tensor\n",
    "* Permute - Returns a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1,9)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(1,9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x (because a view shares the same memory as the orignal).\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other.\n",
    "x_stacked = torch.stack([x, x, x, x])\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Previous shape: torch.Size([1, 9])\n",
      "\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "New shape: torch.Size([9])\n",
      "\n",
      "New tensor: tensor([[5.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n",
      "New shape: torch.Size([9, 1])\n"
     ]
    }
   ],
   "source": [
    "# torch.squeeze() - removes all single dimesnions froma a target tensor\n",
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Removes extra dimensions from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")\n",
    "\n",
    "# Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=1)\n",
    "print(F\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New Shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.peremute rearranges the dimesnions of a target tensor in a specified order.\n",
    "x_orginal = torch.rand(size=(224, 224, 3)) # height, width,colour_channels\n",
    "\n",
    "#Permute the orignal tensor to rearrange the axis (or dim) order\n",
    "x_permuted = x_orginal.permute(2, 0, 1) # shifts the axis 0->1, 1->2, 2->0\n",
    "print(f\"Previous shape: {x_orginal.shape}\")\n",
    "print(f\"New Shape: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8751, 0.9601, 0.9726],\n",
       "         [0.5192, 0.9995, 0.1328],\n",
       "         [0.6704, 0.4730, 0.6087],\n",
       "         ...,\n",
       "         [0.4299, 0.2787, 0.2349],\n",
       "         [0.3240, 0.5001, 0.0015],\n",
       "         [0.6582, 0.3441, 0.3451]],\n",
       "\n",
       "        [[0.5362, 0.0644, 0.7074],\n",
       "         [0.0167, 0.6703, 0.1500],\n",
       "         [0.1136, 0.8952, 0.1865],\n",
       "         ...,\n",
       "         [0.1177, 0.4927, 0.6290],\n",
       "         [0.8594, 0.2095, 0.1340],\n",
       "         [0.7092, 0.0542, 0.2338]],\n",
       "\n",
       "        [[0.2705, 0.7907, 0.6399],\n",
       "         [0.8971, 0.7236, 0.6485],\n",
       "         [0.9161, 0.6005, 0.1863],\n",
       "         ...,\n",
       "         [0.7941, 0.9128, 0.0979],\n",
       "         [0.5161, 0.9778, 0.6048],\n",
       "         [0.1329, 0.5449, 0.2222]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4745, 0.9787, 0.7672],\n",
       "         [0.3577, 0.9113, 0.2401],\n",
       "         [0.6071, 0.2303, 0.6200],\n",
       "         ...,\n",
       "         [0.8207, 0.1970, 0.7752],\n",
       "         [0.2663, 0.8569, 0.7224],\n",
       "         [0.5841, 0.0496, 0.3003]],\n",
       "\n",
       "        [[0.3819, 0.7509, 0.1472],\n",
       "         [0.6817, 0.8863, 0.5096],\n",
       "         [0.9696, 0.8645, 0.9216],\n",
       "         ...,\n",
       "         [0.0624, 0.5866, 0.8410],\n",
       "         [0.2026, 0.6938, 0.2263],\n",
       "         [0.6239, 0.8449, 0.9243]],\n",
       "\n",
       "        [[0.0958, 0.4392, 0.8178],\n",
       "         [0.6298, 0.9460, 0.9957],\n",
       "         [0.1906, 0.9806, 0.3076],\n",
       "         ...,\n",
       "         [0.3672, 0.9246, 0.9204],\n",
       "         [0.9289, 0.4397, 0.4340],\n",
       "         [0.1088, 0.2815, 0.8599]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_orginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal tensor: tensor([[[0.1234, 0.9601, 0.9726],\n",
      "         [0.5192, 0.9995, 0.1328],\n",
      "         [0.6704, 0.4730, 0.6087],\n",
      "         ...,\n",
      "         [0.4299, 0.2787, 0.2349],\n",
      "         [0.3240, 0.5001, 0.0015],\n",
      "         [0.6582, 0.3441, 0.3451]],\n",
      "\n",
      "        [[0.5362, 0.0644, 0.7074],\n",
      "         [0.0167, 0.6703, 0.1500],\n",
      "         [0.1136, 0.8952, 0.1865],\n",
      "         ...,\n",
      "         [0.1177, 0.4927, 0.6290],\n",
      "         [0.8594, 0.2095, 0.1340],\n",
      "         [0.7092, 0.0542, 0.2338]],\n",
      "\n",
      "        [[0.2705, 0.7907, 0.6399],\n",
      "         [0.8971, 0.7236, 0.6485],\n",
      "         [0.9161, 0.6005, 0.1863],\n",
      "         ...,\n",
      "         [0.7941, 0.9128, 0.0979],\n",
      "         [0.5161, 0.9778, 0.6048],\n",
      "         [0.1329, 0.5449, 0.2222]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.4745, 0.9787, 0.7672],\n",
      "         [0.3577, 0.9113, 0.2401],\n",
      "         [0.6071, 0.2303, 0.6200],\n",
      "         ...,\n",
      "         [0.8207, 0.1970, 0.7752],\n",
      "         [0.2663, 0.8569, 0.7224],\n",
      "         [0.5841, 0.0496, 0.3003]],\n",
      "\n",
      "        [[0.3819, 0.7509, 0.1472],\n",
      "         [0.6817, 0.8863, 0.5096],\n",
      "         [0.9696, 0.8645, 0.9216],\n",
      "         ...,\n",
      "         [0.0624, 0.5866, 0.8410],\n",
      "         [0.2026, 0.6938, 0.2263],\n",
      "         [0.6239, 0.8449, 0.9243]],\n",
      "\n",
      "        [[0.0958, 0.4392, 0.8178],\n",
      "         [0.6298, 0.9460, 0.9957],\n",
      "         [0.1906, 0.9806, 0.3076],\n",
      "         ...,\n",
      "         [0.3672, 0.9246, 0.9204],\n",
      "         [0.9289, 0.4397, 0.4340],\n",
      "         [0.1088, 0.2815, 0.8599]]])\n",
      "Permuted tensor: tensor([[[0.1234, 0.5192, 0.6704,  ..., 0.4299, 0.3240, 0.6582],\n",
      "         [0.5362, 0.0167, 0.1136,  ..., 0.1177, 0.8594, 0.7092],\n",
      "         [0.2705, 0.8971, 0.9161,  ..., 0.7941, 0.5161, 0.1329],\n",
      "         ...,\n",
      "         [0.4745, 0.3577, 0.6071,  ..., 0.8207, 0.2663, 0.5841],\n",
      "         [0.3819, 0.6817, 0.9696,  ..., 0.0624, 0.2026, 0.6239],\n",
      "         [0.0958, 0.6298, 0.1906,  ..., 0.3672, 0.9289, 0.1088]],\n",
      "\n",
      "        [[0.9601, 0.9995, 0.4730,  ..., 0.2787, 0.5001, 0.3441],\n",
      "         [0.0644, 0.6703, 0.8952,  ..., 0.4927, 0.2095, 0.0542],\n",
      "         [0.7907, 0.7236, 0.6005,  ..., 0.9128, 0.9778, 0.5449],\n",
      "         ...,\n",
      "         [0.9787, 0.9113, 0.2303,  ..., 0.1970, 0.8569, 0.0496],\n",
      "         [0.7509, 0.8863, 0.8645,  ..., 0.5866, 0.6938, 0.8449],\n",
      "         [0.4392, 0.9460, 0.9806,  ..., 0.9246, 0.4397, 0.2815]],\n",
      "\n",
      "        [[0.9726, 0.1328, 0.6087,  ..., 0.2349, 0.0015, 0.3451],\n",
      "         [0.7074, 0.1500, 0.1865,  ..., 0.6290, 0.1340, 0.2338],\n",
      "         [0.6399, 0.6485, 0.1863,  ..., 0.0979, 0.6048, 0.2222],\n",
      "         ...,\n",
      "         [0.7672, 0.2401, 0.6200,  ..., 0.7752, 0.7224, 0.3003],\n",
      "         [0.1472, 0.5096, 0.9216,  ..., 0.8410, 0.2263, 0.9243],\n",
      "         [0.8178, 0.9957, 0.3076,  ..., 0.9204, 0.4340, 0.8599]]])\n"
     ]
    }
   ],
   "source": [
    "x_orginal[0, 0, 0] = 0.1234\n",
    "print(f\"Orignal tensor: {x_orginal}\")\n",
    "print(f\"Permuted tensor: {x_permuted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing (selecting the data from tensors)\n",
    "Indexing with pytorch is similar as numpy indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1,10).reshape(1,3,3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([1, 2, 3]) tensor([1, 2, 3])\n",
      "tensor(1) tensor(1)\n",
      "tensor(9)\n",
      "tensor([[2, 5, 8]])\n",
      "tensor([5])\n",
      "tensor([1, 2, 3])\n",
      "tensor([[3, 6, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Trying indexes of the tensor\n",
    "print(x[0])\n",
    "print(x[0, 0], x[0][0])\n",
    "print(x[0, 0, 0], x[0][0][0])\n",
    "\n",
    "#Getting element 9\n",
    "print(x[0,2,2])\n",
    "\n",
    "# All values of 0th and 1st dimensions but only index 1 of the second dimension\n",
    "print(x[:, :, 1])\n",
    "\n",
    "# All values of 0th but only index 1 of 1st and 2nd dimension\n",
    "print(x[:, 1, 1])\n",
    "\n",
    "# Get index 0 of 0th and 1st dimension and all values of the 2nd dimension\n",
    "print(x[0, 0, :])\n",
    "\n",
    "# Index on x to return 3, 6, 9\n",
    "print(x[:, :, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch and NumPy\n",
    "\n",
    "NumPy is a popular scientific Python numerical computing library.\n",
    "PyTorch has functionality to interact with it.\n",
    "* Data in numpy, wanted in pytorch sensor -> `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor -> NumPy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy array to tensor\n",
    "array = np.arange(1.0, 8.0) # warning: default dtype of numpy is float 64, default dtype of torch tensors is float 32\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the value of array, what will this do to the `tensor`?\n",
    "array = array + 1\n",
    "array, tensor\n",
    "\n",
    "# Note: nothing changes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to Numpy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = torch.Tensor.numpy(tensor)\n",
    "tensor, numpy_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility (trying to take a random out of random)\n",
    "`start with random numbers -> tensor operations -> update random numbers to try and make them better representations of data -> agian -> again -> again ...`\n",
    "\n",
    "To reduce randomness in nn and PyTorch, random seed concept is used.\n",
    "Essentially what the random seed does is 'flavour' the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6111, 0.8523, 0.9069, 0.9601],\n",
      "        [0.4905, 0.9368, 0.7343, 0.6194],\n",
      "        [0.8698, 0.2298, 0.6398, 0.8342]])\n",
      "tensor([[0.5393, 0.1521, 0.8402, 0.2277],\n",
      "        [0.5587, 0.7882, 0.6096, 0.4627],\n",
      "        [0.7216, 0.2557, 0.8020, 0.8951]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Create 2 random tensors\n",
    "random_tensorA = torch.rand(3,4)\n",
    "random_tensorB = torch.rand(3,4)\n",
    "\n",
    "print(random_tensorA)\n",
    "print(random_tensorB)\n",
    "print(random_tensorA == random_tensorB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Making random but reproducable tensors\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensorC = torch.rand(3,4)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensorD = torch.rand(3,4)\n",
    "\n",
    "print(random_tensorC)\n",
    "print(random_tensorD)\n",
    "print(random_tensorC == random_tensorD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizing GPU\n",
    "GPUs = faster computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch\n",
    "* Use Google collab\n",
    "* Utilizing own GPU\n",
    "* Use cloud computing - GCP, AWS, Azure \n",
    "\n",
    "Since PyTorch is capable on running both CPU and GPU, its a good practice to setup a device agnostic code, i.e use GPU if available else run on cpu `device = \"cuda\" if torch.cuda.is_available() else \"cpu\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Aug 12 17:23:03 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 512.78       Driver Version: 512.78       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   49C    P8     7W /  N/A |    556MiB /  4096MiB |     28%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2012    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      4224    C+G   ...root\\Office16\\WINWORD.EXE    N/A      |\n",
      "|    0   N/A  N/A      9416    C+G   ...v1g1gvanyjgm\\WhatsApp.exe    N/A      |\n",
      "|    0   N/A  N/A      9820    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     12132    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     15384    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     16200    C+G   ...ekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
      "|    0   N/A  N/A     17332    C+G   ..._dt26b99r8h8gj\\RtkUWP.exe    N/A      |\n",
      "|    0   N/A  N/A     18184    C+G   ...8wekyb3d8bbwe\\msteams.exe    N/A      |\n",
      "|    0   N/A  N/A     22192    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     22424    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     24888    C+G   ...4__8j3eq9eme6ctt\\IGCC.exe    N/A      |\n",
      "|    0   N/A  N/A     28080    C+G   ...01.188\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     30876    C+G   ...01.200\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     41724    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     41944    C+G   ...a0\\XboxGameBarSpotify.exe    N/A      |\n",
      "|    0   N/A  N/A     43876    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     45732    C+G   ...t\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     46524    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU access with PyTorch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n",
    "\n",
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting tensors and models on the GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n",
      "tensor([1, 2, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor (default on CPU)\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor, tensor.device)\n",
    "\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "print(tensor_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving tensors back to cpu\n",
    "\n",
    "NumPy only works on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
